"""
–ú–æ–¥—É–ª—å –¥–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel –≤ Neosintez.
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É Excel —Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –ø–æ —É—Ä–æ–≤–Ω—è–º.
"""

import asyncio
import logging
from datetime import datetime
from typing import Any, Dict, List, Optional

import pandas as pd
from pydantic import BaseModel

from neosintez_api.core.exceptions import NeosintezAPIError

from ..core.client import NeosintezClient
from ..core.enums import WioAttributeType
from .class_service import ClassService
from .factories import DynamicModelFactory
from .object_service import CreateRequest, ObjectService


logger = logging.getLogger("neosintez_api.excel_importer")


class ExcelStructure(BaseModel):
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ Excel —Ñ–∞–π–ª–∞ –ø–æ—Å–ª–µ –∞–Ω–∞–ª–∏–∑–∞"""

    level_column: int
    class_column: int
    name_column: int
    attribute_columns: Dict[int, str]
    total_rows: int
    max_level: int
    classes_found: List[str]


class ImportPreview(BaseModel):
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∏–º–ø–æ—Ä—Ç–∞"""

    structure: ExcelStructure
    objects_to_create: List[Dict[str, Any]]
    estimated_objects: int
    validation_errors: List[str]
    validation_warnings: List[str]


class ImportResult(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–ø–æ—Ä—Ç–∞"""

    total_created: int
    created_by_level: Dict[int, int]
    created_objects: List[Dict[str, Any]]
    errors: List[str]
    warnings: List[str]
    duration_seconds: float


class ExcelImporter:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫–æ–≥–æ –∏–º–ø–æ—Ä—Ç–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel –≤ Neosintez.
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É Excel —Ñ–∞–π–ª–∞ –∏ —Å–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –ø–æ —É—Ä–æ–≤–Ω—è–º.
    """

    # –ö–ª—é—á–µ–≤—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
    LEVEL_COLUMN_NAMES = ["–£—Ä–æ–≤–µ–Ω—å", "Level", "–í–ª–æ–∂–µ–Ω–Ω–æ—Å—Ç—å"]
    CLASS_COLUMN_NAMES = ["–ö–ª–∞—Å—Å", "Class", "–¢–∏–ø –æ–±—ä–µ–∫—Ç–∞"]
    NAME_COLUMN_NAMES = ["–ò–º—è –æ–±—ä–µ–∫—Ç–∞", "Name", "–ù–∞–∑–≤–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞", "–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ"]

    def __init__(self, client: NeosintezClient):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–º–ø–æ—Ä—Ç–µ—Ä–∞.

        Args:
            client: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∏–µ–Ω—Ç API Neosintez (–¥–æ–ª–∂–µ–Ω –∏–º–µ—Ç—å —Ä–µ—Å—É—Ä—Å—ã classes –∏ objects)
        """
        self.client = client
        self.object_service = ObjectService(client)
        self.class_service = ClassService(client)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–µ—Ä–≤–∏—Å–Ω—ã–π —Å–ª–æ–π —Å –∫—ç—à–µ–º
        self.factory = DynamicModelFactory(
            client=self.client,
            class_service=self.class_service,  # –ü–µ—Ä–µ–¥–∞–µ–º –æ–±—â–∏–π —ç–∫–∑–µ–º–ø–ª—è—Ä
            name_aliases=self.NAME_COLUMN_NAMES,
            class_name_aliases=self.CLASS_COLUMN_NAMES,
        )
        self._class_attributes_cache: Dict[str, Dict[str, Any]] = {}

    async def analyze_structure(self, excel_path: str, worksheet_name: Optional[str] = None) -> ExcelStructure:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É Excel —Ñ–∞–π–ª–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏.

        Args:
            excel_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
            worksheet_name: –ò–º—è –ª–∏—Å—Ç–∞ –≤ Excel —Ñ–∞–π–ª–µ (–µ—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç)

        Returns:
            ExcelStructure: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

        Raises:
            ApiError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—á–∏—Ç–∞–Ω –∏–ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –Ω–µ–≤–µ—Ä–Ω–∞
        """
        logger.info(f"–ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã —Ñ–∞–π–ª–∞ {excel_path}")

        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º Excel —Ñ–∞–π–ª
            if worksheet_name is None:
                df = pd.read_excel(excel_path, header=None)
            else:
                df = pd.read_excel(excel_path, sheet_name=worksheet_name, header=None)

            logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} —Å—Ç—Ä–æ–∫ –¥–∞–Ω–Ω—ã—Ö")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            has_headers = self._check_headers(df)

            if has_headers:
                headers = [str(cell) for cell in df.iloc[0]]
                data_start_row = 1
            else:
                headers = [f"Column_{i}" for i in range(df.shape[1])]
                data_start_row = 0

            logger.debug(f"–ó–∞–≥–æ–ª–æ–≤–∫–∏: {headers}")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª—é—á–µ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏
            level_column = self._find_column(headers, self.LEVEL_COLUMN_NAMES)
            class_column = self._find_column(headers, self.CLASS_COLUMN_NAMES)
            name_column = self._find_column(headers, self.NAME_COLUMN_NAMES)

            if level_column is None or class_column is None or name_column is None:
                if not has_headers:
                    # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫
                    level_column = 0
                    class_column = 1
                    name_column = 2
                    logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ –∫–æ–ª–æ–Ω–æ–∫: –£—Ä–æ–≤–µ–Ω—å(0), –ö–ª–∞—Å—Å(1), –ò–º—è –æ–±—ä–µ–∫—Ç–∞(2)")
                else:
                    raise NeosintezAPIError("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏: –£—Ä–æ–≤–µ–Ω—å, –ö–ª–∞—Å—Å, –ò–º—è –æ–±—ä–µ–∫—Ç–∞")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ (–≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ)
            used_columns = {level_column, class_column, name_column}
            attribute_columns = {}
            name_columns_lower = [name.lower() for name in self.NAME_COLUMN_NAMES]

            for i in range(len(headers)):
                header_value = str(headers[i]).strip()
                # –ò—Å–∫–ª—é—á–∞–µ–º –ª—é–±—ã–µ –∫–æ–ª–æ–Ω–∫–∏, –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –∏–º—è, –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–æ–≤
                if i not in used_columns and header_value.lower() not in name_columns_lower:
                    if header_value != "" and header_value.lower() not in ["nan", "none"]:
                        attribute_columns[i] = header_value

            logger.debug(f"–ù–∞–π–¥–µ–Ω—ã –∫–æ–ª–æ–Ω–∫–∏ –∞—Ç—Ä–∏–±—É—Ç–æ–≤: {attribute_columns}")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
            data_df = df.iloc[data_start_row:]
            max_level = 0
            classes_found = set()

            for _, row in data_df.iterrows():
                if pd.notna(row.iloc[level_column]):
                    try:
                        level = int(row.iloc[level_column])
                        max_level = max(max_level, level)
                    except (ValueError, TypeError):
                        # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —É—Ä–æ–≤–µ–Ω—å –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —á–∏—Å–ª–æ–º
                        pass

                if pd.notna(row.iloc[class_column]):
                    classes_found.add(str(row.iloc[class_column]))

            return ExcelStructure(
                level_column=level_column,
                class_column=class_column,
                name_column=name_column,
                attribute_columns=attribute_columns,
                total_rows=len(data_df),
                max_level=max_level,
                classes_found=list(classes_found),
            )

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ Excel —Ñ–∞–π–ª–∞: {e}", exc_info=True)
            raise NeosintezAPIError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ Excel —Ñ–∞–π–ª–∞: {e}") from e

    async def preview_import(
        self, excel_path: str, parent_id: str, worksheet_name: Optional[str] = None
    ) -> ImportPreview:
        """
        –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∏–º–ø–æ—Ä—Ç–∞ –±–µ–∑ —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤.

        Args:
            excel_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
            parent_id: ID —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
            worksheet_name: –ò–º—è –ª–∏—Å—Ç–∞ –≤ Excel —Ñ–∞–π–ª–µ

        Returns:
            ImportPreview: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∏–º–ø–æ—Ä—Ç–∞
        """
        logger.info(f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –∏–º–ø–æ—Ä—Ç–∞ –∏–∑ {excel_path}")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        structure = await self.analyze_structure(excel_path, worksheet_name)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏ —Å–æ–±–∏—Ä–∞–µ–º –æ—à–∏–±–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        objects_to_create, loading_errors = await self._load_objects_sequentially(
            excel_path, structure, parent_id, worksheet_name
        )

        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—ä–µ–∫—Ç—ã
        estimated_objects = len(objects_to_create)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        validation_errors, validation_warnings = await self._validate_objects(objects_to_create)
        validation_errors.extend(loading_errors)  # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏, –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ

        return ImportPreview(
            structure=structure,
            objects_to_create=objects_to_create,
            estimated_objects=estimated_objects,
            validation_errors=validation_errors,
            validation_warnings=validation_warnings,
        )

    async def import_from_excel(
        self, excel_path: str, parent_id: str, worksheet_name: Optional[str] = None
    ) -> ImportResult:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –∏–º–ø–æ—Ä—Ç –¥–∞–Ω–Ω—ã—Ö –∏–∑ Excel —Ñ–∞–π–ª–∞.

        Args:
            excel_path: –ü—É—Ç—å –∫ Excel —Ñ–∞–π–ª—É
            parent_id: ID —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
            worksheet_name: –ò–º—è –ª–∏—Å—Ç–∞ –≤ Excel —Ñ–∞–π–ª–µ

        Returns:
            ImportResult: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–ø–æ—Ä—Ç–∞
        """
        start_time = datetime.now()
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∏–º–ø–æ—Ä—Ç –∏–∑ {excel_path} –≤ –æ–±—ä–µ–∫—Ç {parent_id}")

        try:
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
            preview = await self.preview_import(excel_path, parent_id, worksheet_name)

            if preview.validation_errors:
                logger.error(f"–ù–∞–π–¥–µ–Ω—ã –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {preview.validation_errors}")
                return ImportResult(
                    total_created=0,
                    created_by_level={},
                    created_objects=[],
                    errors=preview.validation_errors,
                    warnings=preview.validation_warnings,
                    duration_seconds=(datetime.now() - start_time).total_seconds(),
                )

            # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
            await self._preload_class_metadata(preview.objects_to_create)

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ –ø–æ —É—Ä–æ–≤–Ω—è–º
            created_objects = []
            created_by_level: Dict[int, int] = {}
            errors = []
            warnings = list(preview.validation_warnings)  # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –∏–∑ preview

            # –ù–æ–≤—ã–π —Å–µ—Ç –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è ID –æ–±—ä–µ–∫—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–ª–∏ –±—ã–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω—ã
            failed_or_skipped_virtual_ids = set()

            # –ö–∞—Ä—Ç–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Ä–µ–∞–ª—å–Ω—ã—Ö ID –ø–æ –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–º
            virtual_to_real_id_map: Dict[str, str] = {parent_id: parent_id}

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç—ã –ø–æ —É—Ä–æ–≤–Ω—è–º
            objects_by_level: Dict[int, List[Dict[str, Any]]] = {}
            for obj in preview.objects_to_create:
                level = obj["level"]
                if level not in objects_by_level:
                    objects_by_level[level] = []
                objects_by_level[level].append(obj)

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã, –Ω–∞—á–∏–Ω–∞—è —Å –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è
            for level in sorted(objects_by_level.keys()):
                logger.info(f"–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ {level}")
                requests_to_process = []
                batch_virtual_ids = set()

                for obj_data in objects_by_level[level]:
                    virtual_id = obj_data["virtual_id"]
                    virtual_parent_id = obj_data["parent_id"]

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—ä–µ–∫—Ç, –µ—Å–ª–∏ –µ–≥–æ —Ä–æ–¥–∏—Ç–µ–ª—å –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω
                    if virtual_parent_id in failed_or_skipped_virtual_ids:
                        failed_or_skipped_virtual_ids.add(virtual_id)
                        continue

                    # –ó–∞–º–µ–Ω—è–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π ID –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π
                    real_parent_id = virtual_to_real_id_map.get(virtual_parent_id)

                    if not real_parent_id:
                        # –†–æ–¥–∏—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω, –∑–Ω–∞—á–∏—Ç –≤–µ—Ç–∫–∞ —Å–ª–æ–º–∞–Ω–∞.
                        # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫—É –æ–¥–∏–Ω —Ä–∞–∑ –∏ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –≤—Å—é –≤–µ—Ç–∫—É –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ª–æ–≥–æ–≤.
                        if virtual_parent_id not in failed_or_skipped_virtual_ids:
                            errors.append(
                                f"–ù–µ –Ω–∞–π–¥–µ–Ω —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –æ–±—ä–µ–∫—Ç —Å ID '{virtual_parent_id}' –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è '{obj_data['name']}'. "
                                "–í–µ—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –ø—Ä–æ–ø—É—â–µ–Ω–∞."
                            )
                        failed_or_skipped_virtual_ids.add(virtual_id)
                        continue

                    # --- –ù–û–í–û–ï: –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Ç–∏–ø–æ–≤ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ ---
                    converted_attributes = {}
                    class_name = obj_data["class_name"]
                    attributes_meta = self._class_attributes_cache.get(class_name)

                    if attributes_meta:
                        for attr_name, value in obj_data["attributes"].items():
                            converted_attributes[attr_name] = self._convert_attribute_value(
                                value, attr_name, attributes_meta
                            )
                    else:
                        # –ï—Å–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
                        converted_attributes = obj_data["attributes"]
                    # --- –ö–û–ù–ï–¶ –ù–û–í–û–ì–û –ë–õ–û–ö–ê ---

                    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å Pydantic –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –æ–±—ä–µ–∫—Ç–∞
                    try:
                        # –ì–æ—Ç–æ–≤–∏–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∞–±—Ä–∏–∫–∏
                        user_data_for_factory = {
                            "–ö–ª–∞—Å—Å": obj_data["class_name"],
                            "–ò–º—è –æ–±—ä–µ–∫—Ç–∞": obj_data["name"],
                            **converted_attributes,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç—ã
                        }
                        # –§–∞–±—Ä–∏–∫–∞ –≤–µ—Ä–Ω–µ—Ç "—á–µ—Ä—Ç–µ–∂" —Å –≥–æ—Ç–æ–≤–æ–π –º–æ–¥–µ–ª—å—é
                        blueprint = await self.factory.create(user_data_for_factory)

                        # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –≤ —Å–ø–∏—Å–æ–∫ –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É,
                        # –ø–µ—Ä–µ–¥–∞–≤–∞—è –≤—Å—é –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –º–µ—Ç–∞-–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                        request = CreateRequest(
                            model=blueprint.model_instance,
                            class_id=blueprint.class_id,
                            class_name=blueprint.class_name,
                            attributes_meta=blueprint.attributes_meta,
                            parent_id=real_parent_id,
                            virtual_id=obj_data["virtual_id"],
                        )
                        requests_to_process.append(request)
                        batch_virtual_ids.add(request.virtual_id)

                    except Exception as e:
                        error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—ä–µ–∫—Ç–∞ '{obj_data['name']}': {e}"
                        logger.error(error_msg, exc_info=True)
                        errors.append(error_msg)
                        # –ï—Å–ª–∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å, —Å—á–∏—Ç–∞–µ–º –æ–±—ä–µ–∫—Ç —Å–±–æ–π–Ω—ã–º
                        failed_or_skipped_virtual_ids.add(obj_data["virtual_id"])

                if not requests_to_process:
                    continue

                # –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ï –ø–∞–∫–µ—Ç–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —Ç–µ–∫—É—â–µ–º —É—Ä–æ–≤–Ω–µ
                try:
                    # –ü–æ–ª—É—á–∞–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                    from neosintez_api.config import PerformanceSettings

                    perf_settings = PerformanceSettings.get_optimized_settings(len(requests_to_process))

                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é create_many_optimized
                    creation_result = await self.object_service.create_many_optimized(
                        requests_to_process,
                        max_concurrent_create=perf_settings["max_concurrent_create"],
                        max_concurrent_attrs=perf_settings["max_concurrent_attrs"],
                    )

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    succeeded_virtual_ids = set()
                    for created_model in creation_result.created_models:
                        # –ù–∞—Ö–æ–¥–∏–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ –∏–Ω—Å—Ç–∞–Ω—Å—É –º–æ–¥–µ–ª–∏.
                        # –≠—Ç–æ –Ω–∞–¥–µ–∂–Ω–æ, —Ç–∞–∫ –∫–∞–∫ ObjectService –º—É—Ç–∏—Ä—É–µ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –æ–±—ä–µ–∫—Ç.
                        requests_iter = (req for req in requests_to_process if req.model is created_model)
                        original_request = next(requests_iter, None)

                        if original_request:
                            virtual_id = original_request.virtual_id
                            real_id = created_model._id
                            virtual_to_real_id_map[virtual_id] = real_id
                            succeeded_virtual_ids.add(virtual_id)

                            # –ò—â–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–æ virtual_id –¥–ª—è –æ—Ç—á–µ—Ç–∞
                            source_data = next(
                                (obj for obj in preview.objects_to_create if obj.get("virtual_id") == virtual_id), {}
                            )
                            created_objects.append(
                                {
                                    "id": real_id,
                                    "name": created_model.name,
                                    "class_name": created_model.Neosintez.class_name,
                                    "level": source_data.get("level", -1),
                                }
                            )
                            created_by_level[level] = created_by_level.get(level, 0) + 1
                        else:
                            logger.warning(
                                f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–Ω–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ —Å ID {created_model._id}"
                            )

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–±–æ–∏ –Ω–∞ —É—Ä–æ–≤–Ω–µ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω–∏—Ü—É –º–Ω–æ–∂–µ—Å—Ç–≤
                    level_failures = batch_virtual_ids - succeeded_virtual_ids
                    failed_or_skipped_virtual_ids.update(level_failures)

                    # –î–æ–±–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏
                    if creation_result.errors:
                        errors.extend(creation_result.errors)

                except Exception as e:
                    error_msg = f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞–∫–µ—Ç–Ω–æ–º —Å–æ–∑–¥–∞–Ω–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ —É—Ä–æ–≤–Ω–µ {level}: {e}"
                    logger.error(error_msg, exc_info=True)
                    errors.append(error_msg)
                    # –ï—Å–ª–∏ –≤—Å—è –ø–∞—á–∫–∞ —É–ø–∞–ª–∞, –≤—Å–µ ID –≤ –Ω–µ–π —Å—á–∏—Ç–∞—é—Ç—Å—è —Å–±–æ–π–Ω—ã–º–∏
                    failed_or_skipped_virtual_ids.update(batch_virtual_ids)

            duration = (datetime.now() - start_time).total_seconds()
            logger.info(f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω –∑–∞ {duration:.2f} —Å–µ–∫.")

            self._log_import_statistics(
                ImportResult(
                    total_created=len(created_objects),
                    created_by_level=created_by_level,
                    created_objects=created_objects,
                    errors=errors,
                    warnings=warnings,
                    duration_seconds=duration,
                ),
                preview,
                duration,
                duration,  # –í—Ä–µ–º—è –∏–º–ø–æ—Ä—Ç–∞ —Ä–∞–≤–Ω–æ –æ–±—â–µ–º—É –≤—Ä–µ–º–µ–Ω–∏
            )

            return ImportResult(
                total_created=len(created_objects),
                created_by_level=created_by_level,
                created_objects=created_objects,
                errors=errors,
                warnings=warnings,
                duration_seconds=duration,
            )

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏–º–ø–æ—Ä—Ç–∞: {e}", exc_info=True)
            return ImportResult(
                total_created=0,
                created_by_level={},
                created_objects=[],
                errors=[f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}"],
                warnings=[],
                duration_seconds=(datetime.now() - start_time).total_seconds(),
            )

    def _check_headers(self, df: pd.DataFrame) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ DataFrame –∑–∞–≥–æ–ª–æ–≤–∫–∏."""
        if df.empty:
            return False
        first_row = df.iloc[0]
        # –ü—Ä–æ—Å—Ç–æ–π —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: –µ—Å–ª–∏ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ —è—á–µ–µ–∫ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ - —Å—Ç—Ä–æ–∫–∏,
        # —Ç–æ —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —ç—Ç–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏.
        string_cells = sum(isinstance(cell, str) for cell in first_row)
        return string_cells / len(first_row) > 0.5

    def _find_column(self, headers: List[str], column_names: List[str]) -> Optional[int]:
        """–ù–∞—Ö–æ–¥–∏—Ç –∏–Ω–¥–µ–∫—Å –∫–æ–ª–æ–Ω–∫–∏ –ø–æ –æ–¥–Ω–æ–º—É –∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∏–º–µ–Ω."""
        headers_lower = [str(h).lower() for h in headers]
        names_lower = [str(n).lower() for n in column_names]
        for name in names_lower:
            if name in headers_lower:
                return headers_lower.index(name)
        return None

    async def _load_objects_sequentially(
        self,
        excel_path: str,
        structure: ExcelStructure,
        parent_id: str,
        worksheet_name: Optional[str] = None,
    ) -> tuple[List[Dict[str, Any]], List[str]]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –∏–∑ Excel –∏ —Å—Ç—Ä–æ–∏—Ç –∏–µ—Ä–∞—Ä—Ö–∏—á–µ—Å–∫—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –∏ —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫, –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ.
        """
        if structure.total_rows == 0:
            return [], []

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        try:
            # –ß–∏—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –ª–∏—Å—Ç, –µ—Å–ª–∏ –∏–º—è –Ω–µ —É–∫–∞–∑–∞–Ω–æ
            sheet_to_read = worksheet_name or 0

            # –°–Ω–∞—á–∞–ª–∞ —á–∏—Ç–∞–µ–º –±–µ–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤, —á—Ç–æ–±—ã –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Ö –Ω–∞–ª–∏—á–∏–µ
            df_no_header = pd.read_excel(excel_path, sheet_name=sheet_to_read, header=None)

            if self._check_headers(df_no_header):
                # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –µ—Å—Ç—å, –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞–µ–º —Å –Ω–∏–º–∏
                df = pd.read_excel(excel_path, sheet_name=sheet_to_read, header=0)
            else:
                # –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ –µ—Å—Ç—å, —Å —á–∏—Å–ª–æ–≤—ã–º–∏ –∏–Ω–¥–µ–∫—Å–∞–º–∏ –∫–æ–ª–æ–Ω–æ–∫
                df = df_no_header

        except Exception as e:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel —Ñ–∞–π–ª: {e}", exc_info=True)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä –∏—Å–∫–ª—é—á–µ–Ω–∏—è
            raise NeosintezAPIError(message=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å Excel —Ñ–∞–π–ª: {e}", status_code=400) from e

        objects_to_create = []
        errors = []
        parent_map: Dict[int, str] = {0: parent_id}  # level -> virtual_id
        virtual_id_counter = 0

        for index, row in df.iterrows():
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ –Ω–µ—Ç –¥–∞–∂–µ —É—Ä–æ–≤–Ω—è
            if pd.isna(row.iloc[structure.level_column]):
                continue

            try:
                level = int(row.iloc[structure.level_column])

                class_name_raw = row.iloc[structure.class_column]
                name_raw = row.iloc[structure.name_column]

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∫–ª–∞—Å—Å–∞ –∏–ª–∏ –∏–º–µ–Ω–∏. –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞.
                if (
                    pd.isna(class_name_raw)
                    or str(class_name_raw).strip().lower() in ("", "nan")
                    or pd.isna(name_raw)
                    or str(name_raw).strip() == ""
                ):
                    error_msg = f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–ö–ª–∞—Å—Å –∏–ª–∏ –ò–º—è –æ–±—ä–µ–∫—Ç–∞)."
                    logger.error(error_msg)
                    errors.append(error_msg)
                    continue

                class_name = str(class_name_raw)
                name = str(name_raw)

                # –°–æ–∑–¥–∞–µ–º –≤–∏—Ä—Ç—É–∞–ª—å–Ω—ã–π ID –¥–ª—è —ç—Ç–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞
                virtual_id_counter += 1
                virtual_id = f"virtual::{virtual_id_counter}"

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—è
                current_parent_id = parent_map.get(level - 1)
                if not current_parent_id:
                    # --- –ò–ó–ú–ï–ù–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê ---
                    # –í–º–µ—Å—Ç–æ –ø–µ—Ä–µ–Ω–∞–∑–Ω–∞—á–µ–Ω–∏—è —Ä–æ–¥–∏—Ç–µ–ª—è, —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –∫–∞–∫ –æ—à–∏–±–∫—É
                    max_level_before_jump = max(parent_map.keys()) if parent_map else 0
                    error_msg = (
                        f"–°—Ç—Ä–æ–∫–∞ {index + 2}: –ù–∞—Ä—É—à–µ–Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏—è. "
                        f"–û–±—ä–µ–∫—Ç '{name}' —É—Ä–æ–≤–Ω—è {level} –Ω–µ –º–æ–∂–µ—Ç —Å–ª–µ–¥–æ–≤–∞—Ç—å –∑–∞ —É—Ä–æ–≤–Ω–µ–º {max_level_before_jump}."
                    )
                    logger.error(error_msg)
                    errors.append(error_msg)
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç—É —Å—Ç—Ä–æ–∫—É

                # –°–æ–±–∏—Ä–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã
                attributes = {}
                for col_index, attr_name in structure.attribute_columns.items():
                    if col_index < len(row):
                        value = row.iloc[col_index]
                        if pd.notna(value) and value != "":
                            attributes[attr_name] = value

                objects_to_create.append(
                    {
                        "row_index": index + 2,  # +1 –∑–∞ header, +1 –∑–∞ 0-–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é
                        "level": level,
                        "class_name": class_name,
                        "name": name,
                        "parent_id": current_parent_id,
                        "virtual_id": virtual_id,
                        "attributes": attributes,
                    }
                )

                # –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ä—Ç—É —Ä–æ–¥–∏—Ç–µ–ª—è –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —É—Ä–æ–≤–Ω—è
                parent_map[level] = virtual_id

            except (ValueError, IndexError) as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–æ–∫–∏ {index + 2}: {e}", exc_info=True)
                continue

        return objects_to_create, errors

    async def _validate_objects(self, objects_to_create: List[Dict[str, Any]]) -> tuple[List[str], List[str]]:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –æ–±—ä–µ–∫—Ç—ã –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º, –∏—Å–ø–æ–ª—å–∑—É—è –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π ClassService.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ_–æ—à–∏–±–∫–∏, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è).
        """
        warnings: List[str] = []
        errors: List[str] = []

        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–µ—Ä–∞—Ä—Ö–∏—é
            last_level = 0
            for i, obj_data in enumerate(objects_to_create):
                level = obj_data.get("level")
                if level is None:
                    errors.append(f"–í —Å—Ç—Ä–æ–∫–µ {i + 2} –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è.")
                    continue

                if level > last_level + 1:
                    error_msg = (
                        f"–ù–∞—Ä—É—à–µ–Ω–∞ –∏–µ—Ä–∞—Ä—Ö–∏—è –≤ —Å—Ç—Ä–æ–∫–µ {i + 2}: "
                        f"—É—Ä–æ–≤–Ω—è {level} –Ω–µ –º–æ–∂–µ—Ç —Å–ª–µ–¥–æ–≤–∞—Ç—å –∑–∞ —É—Ä–æ–≤–Ω–µ–º {last_level}. "
                        "–ü—Ä–æ–ø—É—â–µ–Ω –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—Ä–æ–≤–Ω–µ–π."
                    )
                    errors.append(error_msg)
                    # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –¥–∞–ª—å–Ω–µ–π—à—É—é –ø—Ä–æ–≤–µ—Ä–∫—É, —Ç–∞–∫ –∫–∞–∫ –∏–µ—Ä–∞—Ä—Ö–∏—è —É–∂–µ –Ω–∞—Ä—É—à–µ–Ω–∞
                    return errors, warnings
                last_level = level

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã
            for obj_data in objects_to_create:
                class_name = obj_data.get("class_name")
                if not class_name:
                    continue  # –û—à–∏–±–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫–ª–∞—Å—Å–∞ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –≤ _load_objects_sequentially

                # –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞
                # –ï—Å–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã, –∑–∞–≥—Ä—É–∂–∞–µ–º –∏—Ö (—Ä–µ–∑–µ—Ä–≤–Ω—ã–π –ø—É—Ç—å)
                if class_name not in self._class_attributes_cache:
                    try:
                        found_classes = await self.class_service.find_by_name(class_name)
                        # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–º–µ–Ω–∏, –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É
                        class_info = next((c for c in found_classes if c.Name.lower() == class_name.lower()), None)

                        if class_info:
                            class_attributes = await self.class_service.get_attributes(str(class_info.Id))
                            self._class_attributes_cache[class_name] = {attr.Name: attr for attr in class_attributes}
                        else:
                            self._class_attributes_cache[class_name] = None
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∞—Ç—Ä–∏–±—É—Ç—ã –¥–ª—è –∫–ª–∞—Å—Å–∞ '{class_name}': {e}")
                        self._class_attributes_cache[class_name] = None
                        continue

                attributes_meta = self._class_attributes_cache[class_name]
                if not attributes_meta:
                    if f"–ö–ª–∞—Å—Å '{class_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ." not in errors:
                        errors.append(f"–ö–ª–∞—Å—Å '{class_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ.")
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ –∫–ª–∞—Å—Å–µ
                for attr_name in obj_data.get("attributes", {}):
                    if attr_name not in attributes_meta:
                        warning_msg = f"–ê—Ç—Ä–∏–±—É—Ç '{attr_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –∫–ª–∞—Å—Å–µ '{class_name}' –∏ –±—É–¥–µ—Ç –ø—Ä–æ–∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω."
                        if warning_msg not in warnings:
                            warnings.append(warning_msg)
                    else:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∞—Ç—Ä–∏–±—É—Ç —Ñ–∞–π–ª–æ–≤—ã–º
                        attr_meta = attributes_meta[attr_name]
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º getattr –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ Type, —Ç.–∫. –æ–Ω –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å
                        attr_type = getattr(attr_meta, "Type", None)
                        # –í –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ API —Ç–∏–ø –º–æ–∂–µ—Ç –±—ã—Ç—å –∫–∞–∫ int, —Ç–∞–∫ –∏ –æ–±—ä–µ–∫—Ç–æ–º AttributeType
                        if isinstance(attr_type, BaseModel) and hasattr(attr_type, "Id"):
                            attr_type_id = attr_type.Id
                        else:
                            attr_type_id = attr_type

                        if attr_type_id == 7:  # WioAttributeType.FILE.value
                            warning_msg = (
                                f"–ê—Ç—Ä–∏–±—É—Ç '{attr_name}' –≤ –∫–ª–∞—Å—Å–µ '{class_name}' —è–≤–ª—è–µ—Ç—Å—è —Ñ–∞–π–ª–æ–≤—ã–º –∏ –±—É–¥–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω. "
                                "–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤ –ø–æ–∫–∞ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è."
                            )
                            if warning_msg not in warnings:
                                warnings.append(warning_msg)

        except NeosintezAPIError as e:
            logger.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ API –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}", exc_info=True)
            errors.append(f"–û—à–∏–±–∫–∞ API –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e.detail or e.message}")
        except Exception as e:
            logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}", exc_info=True)
            errors.append(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")

        return errors, warnings

    def _convert_attribute_value(self, value: Any, attr_name: str, attributes_meta: Dict[str, Any]) -> Any:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –∞—Ç—Ä–∏–±—É—Ç–∞ –≤ —Ü–µ–ª–µ–≤–æ–π —Ç–∏–ø Neosintez.

        Args:
            value: –ò—Å—Ö–æ–¥–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ Excel.
            attr_name: –ò–º—è –∞—Ç—Ä–∏–±—É—Ç–∞.
            attributes_meta: –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –∫–ª–∞—Å—Å–∞.

        Returns:
            –°–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ.
        """
        if value is None or pd.isna(value):
            return None

        attr_meta = attributes_meta.get(attr_name)
        if not attr_meta:
            # –ï—Å–ª–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
            return value

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID —Ç–∏–ø–∞ –∞—Ç—Ä–∏–±—É—Ç–∞
        attr_type_obj = getattr(attr_meta, "Type", None)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Type - —ç—Ç–æ –æ–±—ä–µ–∫—Ç Pydantic —Å –ø–æ–ª–µ–º Id, –∏–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–∞–∫ –µ—Å—Ç—å
        if isinstance(attr_type_obj, BaseModel) and hasattr(attr_type_obj, "Id"):
            attr_type_id = attr_type_obj.Id
        else:
            attr_type_id = attr_type_obj

        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        if attr_type_id in (WioAttributeType.STRING.value, WioAttributeType.TEXT.value):
            # –ï—Å–ª–∏ —Ü–µ–ª–µ–≤–æ–π —Ç–∏–ø - —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ —Ç–µ–∫—Å—Ç, –ø—Ä–∏–≤–æ–¥–∏–º –∫ —Å—Ç—Ä–æ–∫–µ
            return str(value)
        # TODO: –î–æ–±–∞–≤–∏—Ç—å –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—é –¥–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ (NUMBER, DATE, etc.) –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

        # –ï—Å–ª–∏ —Ç–∏–ø –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return value

    async def _preload_class_metadata(self, objects_to_create: List[Dict[str, Any]]) -> None:
        """
        –û–ü–¢–ò–ú–ò–ó–ê–¶–ò–Ø: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –∫—ç—à–∏—Ä—É–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤
        –∏–∑ —Å–ø–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è. –≠—Ç–æ –∏—Å–∫–ª—é—á–∞–µ—Ç –ø–æ–≤—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –∫ API.

        Args:
            objects_to_create: –°–ø–∏—Å–æ–∫ –æ–±—ä–µ–∫—Ç–æ–≤ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è
        """
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª–∞—Å—Å—ã
        unique_classes = set()
        for obj_data in objects_to_create:
            class_name = obj_data.get("class_name")
            if class_name and class_name not in self._class_attributes_cache:
                unique_classes.add(class_name)

        if not unique_classes:
            logger.info("–í—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å–æ–≤ —É–∂–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω—ã")
            return

        logger.info(f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è {len(unique_classes)} –∫–ª–∞—Å—Å–æ–≤: {list(unique_classes)}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        async def load_class_metadata(class_name: str) -> tuple[str, Optional[Dict[str, Any]]]:
            """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ –∫–ª–∞—Å—Å–∞"""
            try:
                found_classes = await self.class_service.find_by_name(class_name)
                # –ò—â–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∏–º–µ–Ω–∏, –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É
                class_info = next((c for c in found_classes if c.Name.lower() == class_name.lower()), None)

                if class_info:
                    class_attributes = await self.class_service.get_attributes(str(class_info.Id))
                    attributes_meta = {attr.Name: attr for attr in class_attributes}
                    logger.debug(f"–ó–∞–≥—Ä—É–∂–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–ª–∞—Å—Å–∞ '{class_name}': {len(attributes_meta)} –∞—Ç—Ä–∏–±—É—Ç–æ–≤")
                    return class_name, attributes_meta
                else:
                    logger.warning(f"–ö–ª–∞—Å—Å '{class_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–∏—Å—Ç–µ–º–µ")
                    return class_name, None
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–ª–∞—Å—Å–∞ '{class_name}': {e}")
                return class_name, None

        # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        tasks = [load_class_metadata(class_name) for class_name in unique_classes]
        results = await asyncio.gather(*tasks, return_exceptions=False)

        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        for class_name, attributes_meta in results:
            self._class_attributes_cache[class_name] = attributes_meta

        loaded_count = sum(1 for _, meta in results if meta is not None)
        logger.info(
            f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {loaded_count}/{len(unique_classes)} –∫–ª–∞—Å—Å–æ–≤ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã"
        )

    def _log_import_statistics(
        self, result: "ImportResult", preview: "ImportPreview", total_time: float, import_time: float
    ) -> None:
        """
        –ù–û–í–û–ï: –õ–æ–≥–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–º–ø–æ—Ä—Ç–∞.

        Args:
            result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∏–º–ø–æ—Ä—Ç–∞
            preview: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä
            total_time: –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            import_time: –í—Ä–µ–º—è –∏–º–ø–æ—Ä—Ç–∞ –±–µ–∑ preview
        """
        logger.info("=" * 80)
        logger.info("üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –ò–ú–ü–û–†–¢–ê")
        logger.info("=" * 80)

        # –ë–∞–∑–æ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {result.total_created}")
        logger.info(f"‚è±Ô∏è  –í—Ä–µ–º—è –∏–º–ø–æ—Ä—Ç–∞: {import_time:.2f} —Å–µ–∫")
        logger.info(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")

        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        if result.total_created > 0:
            avg_time = import_time / result.total_created
            logger.info(f"üìä –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –Ω–∞ –æ–±—ä–µ–∫—Ç: {avg_time:.3f} —Å–µ–∫")

            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å baseline (0.43 —Å–µ–∫/–æ–±—ä–µ–∫—Ç –¥–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π)
            baseline_time = 0.43
            improvement = ((baseline_time - avg_time) / baseline_time) * 100
            speedup = baseline_time / avg_time

            logger.info(f"üöÄ –£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {improvement:.1f}%")
            logger.info(f"üéØ –£—Å–∫–æ—Ä–µ–Ω–∏–µ –≤ {speedup:.1f}x —Ä–∞–∑")

            # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–ø—É—Å–∫–Ω–æ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
            throughput = 3600 / avg_time  # –æ–±—ä–µ–∫—Ç–æ–≤ –≤ —á–∞—Å
            logger.info(f"üìà –ü—Ä–æ–ø—É—Å–∫–Ω–∞—è —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å: {throughput:.0f} –æ–±—ä–µ–∫—Ç–æ–≤/—á–∞—Å")

        # –î–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —É—Ä–æ–≤–Ω—è–º
        logger.info("\nüìä –û–±—ä–µ–∫—Ç–æ–≤ –ø–æ —É—Ä–æ–≤–Ω—è–º:")
        for level, count in sorted(result.created_by_level.items()):
            logger.info(f"   - –£—Ä–æ–≤–µ–Ω—å {level}: {count} –æ–±—ä–µ–∫—Ç–æ–≤")

        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π
        logger.info("\nüöÄ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
        logger.info("   ‚úÖ –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–µ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤")
        logger.info("   ‚úÖ –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –æ–¥–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è")
        logger.info("   ‚úÖ Batch —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∞—Ç—Ä–∏–±—É—Ç–æ–≤")
        logger.info("   ‚úÖ –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ concurrent —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π")

        # –ö–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
        total_warnings = len(result.warnings)
        total_errors = len(result.errors)

        if total_warnings > 0:
            logger.info(f"\n‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {total_warnings}")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ –≤ –ª–æ–≥–∞—Ö
            for warning in result.warnings[:3]:
                logger.info(f"   - {warning}")
            if total_warnings > 3:
                logger.info(f"   ... –∏ –µ—â—ë {total_warnings - 3}")

        if total_errors > 0:
            logger.info(f"\n‚ùå –û—à–∏–±–∫–∏: {total_errors}")
            for error in result.errors[:3]:
                logger.info(f"   - {error}")
            if total_errors > 3:
                logger.info(f"   ... –∏ –µ—â—ë {total_errors - 3}")

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–±—ä–µ–∫—Ç—ã —Å–æ–∑–¥–∞–≤–∞–ª–∏—Å—å)
        if result.total_created > 0:
            avg_time = import_time / result.total_created
            if avg_time > 0.15:  # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –º–µ–¥–ª–µ–Ω–Ω–æ
                logger.info("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–π –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:")
                logger.info("   - –£–≤–µ–ª–∏—á–∏—Ç—å max_concurrent –¥–ª—è –Ω–µ–±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤")
                logger.info("   - –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å batch API endpoints –≤ –±—É–¥—É—â–∏—Ö –≤–µ—Ä—Å–∏—è—Ö Neosintez")

        logger.info("=" * 80)
